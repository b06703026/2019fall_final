{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import jieba\n",
    "import re\n",
    "# AllDocRoot 為 所有評論所在資料夾\n",
    "AllDocRoot = r\"C:\\Users\\User\\Desktop\\商管\\Final\\TenReviews\"\n",
    "#CP值的csv轉成utf-8 的txt所在位置\n",
    "CPPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\CP.txt'\n",
    "EnvironmentPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\環境.txt'\n",
    "ServicePath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\服務.txt'\n",
    "DelicacyPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\美味.txt'\n",
    "#  務必下載斷詞字典和停用詞字典放到以下位置\n",
    "SepDictionaryPath = r'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\jieba\\dict.txt'\n",
    "StopDicPath = r'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\jieba\\stop.txt'\n",
    "jieba.set_dictionary(r'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\jieba\\dict.txt')\n",
    "\n",
    "with open(StopDicPath,'r',encoding = 'utf8') as f:\n",
    "    StopWords = f.read().split('\\n')\n",
    "    StopWords[0] = ','\n",
    "    \n",
    "def ChiFeatureSelection(Corpus_list,dic_list,Class_group, n ):\n",
    "    '''\n",
    "    Feautures Selection的方法\n",
    "    Input:Corpus_list, [0] 為標記 0,1 [1]為斷詞後評論\n",
    "          dic_list, set of terms\n",
    "          Class_group, 共幾組，以list表示 i.e. ['0','1']\n",
    "          n, 前幾名term\n",
    "    '''\n",
    "    goodfeatures = []\n",
    "    for term in dic_list:\n",
    "        Xchi = 0\n",
    "        ContingencyTable = []\n",
    "        Tcount= 0\n",
    "        Fcount = 0\n",
    "        for Class in Class_group:\n",
    "            TP = 0\n",
    "            FN = 0\n",
    "            for corpus in Corpus_list:\n",
    "                \n",
    "                if term in corpus[1] and Class == corpus[0]:\n",
    "                    TP += 1\n",
    "                elif term not in corpus[1] and Class == corpus[0]:\n",
    "                    FN += 1\n",
    "            Tcount += TP\n",
    "            Fcount += FN\n",
    "            ContingencyTable.append([TP,FN])\n",
    "#             print(Class)\n",
    "            \n",
    "        Total = (Tcount + Fcount) \n",
    "        T_P = Tcount / Total\n",
    "        N_P = 1 - T_P\n",
    "#         print(T_P,N_P,sep=' ')\n",
    "        for i in ContingencyTable:\n",
    "            T = i[0]\n",
    "            F = i[1]\n",
    "            Class_P = (T + F)/ Total\n",
    "            \n",
    "            Etc = T_P * Class_P\n",
    "            Efc = N_P * Class_P\n",
    "            if N_P ==0:\n",
    "                print(N_P )\n",
    "            Xchi += (T - Etc)**(2) / Etc + (F - Efc)**(2) / Efc\n",
    "        goodfeatures.append([term,Xchi])\n",
    "        goodfeatures.sort(reverse = True, key = lambda x:x[1])\n",
    "        goodfeatures_term = []\n",
    "        for i in goodfeatures:\n",
    "            goodfeatures_term.append(i[0])\n",
    "    return goodfeatures_term[0:n]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    import jieba\n",
    "    \n",
    "    def __init__(self,Path):\n",
    "        '''\n",
    "        Input: Path, 為訓練集的位置的，UTF-8 txt\n",
    "        Output: Positive, 正面(1)或負面(0)\n",
    "                Name, 店家名\n",
    "                Counter ,該店家第幾篇評論\n",
    "        '''\n",
    "        Corpus = []\n",
    "        with open(Path,'r', encoding = 'utf-8') as text:\n",
    "        #     text.close()\n",
    "            PositiveList = []\n",
    "            NameList = []\n",
    "            CounterList = []\n",
    "            for i in text:\n",
    "                Positive = i.strip('\\n').split('\\t')[0]\n",
    "                Positive = Positive.strip('\\ufeff')\n",
    "                Name = i.strip('\\n').split('\\t')[1].split(',')[0]\n",
    "                Id =int(i.strip('\\n').split('\\t')[1].split(',')[1])\n",
    "                PositiveList.append(Positive)\n",
    "                NameList.append(Name)\n",
    "                CounterList.append(Id)\n",
    "                \n",
    "        self.Positive = PositiveList\n",
    "        self.Name= NameList\n",
    "        self.Counter = CounterList\n",
    "        \n",
    "    def BuildTrainDic(self,ALLDocsRoot,n):\n",
    "        '''\n",
    "        Input:  ALLDocsRoot, 為所有評論的位置，評論為json檔\n",
    "                Positive, 正面(1)或負面(0)\n",
    "                Name, 店家名\n",
    "                Counter ,該店家第幾篇評論\n",
    "                皆為上述產生\n",
    "                n, 前n名的Feautures\n",
    "        Ootput:\n",
    "                self.TopNFeautures,前n名的Feautures\n",
    "                \n",
    "        41~70 對你找出資料夾中訓練集的文章並清掉韓文有幫助，71是結疤斷詞\n",
    "        '''\n",
    "        file_list = glob.glob(os.path.join(os.getcwd(), ALLDocsRoot, \"*.json\"))\n",
    "        Corpus = []\n",
    "        NegativeCorpus = []\n",
    "        NameAndPositive = []\n",
    "        Potential_Features = []\n",
    "        Potential_GFeatures = []\n",
    "        Potential_NFeatures = []\n",
    "        for i in zip(self.Positive,self.Name):\n",
    "            NameAndPositive.append([i[1],i[0]])\n",
    "       \n",
    "        for file_path in file_list:\n",
    "            BaseName = file_path.split('\\\\')[-1].strip('.json')\n",
    "            for NamePositiveAndOrder in zip(NameAndPositive,self.Counter):\n",
    "#                 print(NamePositiveAndOrder[0][0],BaseName)\n",
    "                if BaseName == NamePositiveAndOrder[0][0] :                   \n",
    "                    with open(file_path,encoding = 'utf-8') as load_test:\n",
    "                        doc =json.load(load_test)\n",
    "                        \n",
    "                        if len(doc['reviews']) != 0:\n",
    "                            \n",
    "                            for i in range(len(doc['reviews'])):\n",
    "                                if i == NamePositiveAndOrder[1]:\n",
    "                                    \n",
    "                                    Text = doc['reviews'][i]['text']\n",
    "                                    Text = re.findall(r'[\\u4e00-\\u9fff]+', Text)\n",
    "                                    Sisstring = ''\n",
    "                                    for i in Text:\n",
    "                                        Sisstring += i \n",
    "                                    words = [s for s in jieba.cut(Sisstring, cut_all=False) if s not in StopWords]\n",
    "                                    if NamePositiveAndOrder[0][1] == '1':\n",
    "                                        Corpus.append([NamePositiveAndOrder[0][1],words])\n",
    "                                        Potential_GFeatures.extend(words)\n",
    "                                        Potential_Features.extend(words)\n",
    "                                    elif NamePositiveAndOrder[0][1] == '0':\n",
    "                                        Corpus.append([NamePositiveAndOrder[0][1],words])\n",
    "                                        Potential_NFeatures.extend(words)\n",
    "                                        Potential_Features.extend(words)\n",
    "                                    else:\n",
    "                                        return print('Indicatior is neither 1 or 0')\n",
    "\n",
    "        self.Potential_Features = set(Potential_Features)\n",
    "        self.GoodFeatures = set(Potential_GFeatures)\n",
    "        self.NegativeFeatures = set(Potential_NFeatures)\n",
    "        \n",
    "        Class_group= ['0','1']\n",
    "        \n",
    "        self.TopNFeautures = ChiFeatureSelection(Corpus, self.Potential_Features,Class_group, n)\n",
    "        self.TopNGood = ChiFeatureSelection(Corpus, self.GoodFeatures,Class_group, n)\n",
    "        self.TopNNegative = ChiFeatureSelection(Corpus, self.NegativeFeatures,Class_group, n)\n",
    "        \n",
    "#                 CorpusPerReviewTemp = []\n",
    "#                 CorpusPerVendorTemp= []\n",
    "#                 AvgRate = 0\n",
    "#                 Rate = None\n",
    "#                 if len(doc['reviews']) == 0:\n",
    "#                     for i in range(len(doc['reviews'])):\n",
    "\n",
    "#                         if CounterForSampling in SampleList:\n",
    "\n",
    "#                             Rate = float(doc['reviews'][i]['rating'])\n",
    "#                             AvgRate += Rate\n",
    "#                             TextRaw = doc['reviews'][i]['text']\n",
    "\n",
    "#                             if '(원본)' in TextRaw :\n",
    "#                                 TextChinese = TextRaw.split('(원본)')[-1]\n",
    "#                             else:\n",
    "#                                 TextChinese = TextRaw\n",
    "\n",
    "#                             TextChineseRemoveN = TextChinese.replace('\\n','')\n",
    "#                             CorpusPerReviewTemp.append([Rate,TextChineseRemoveN])\n",
    "#                             CorpusPerVendorTemp.append(TextChineseRemoveN)\n",
    "\n",
    "#                              CounterForSampling +=1\n",
    "\n",
    "#                     AvgRate = AvgRate / len(doc['reviews'])     \n",
    "#                     CorpusPerVendor[BaseName] = [AvgRate,CorpusPerVendorTemp] \n",
    "#                     CorpusPerReview[BaseName] = \"\".join(CorpusPerVendorTemp)\n",
    "#                     AllCorpus.extend(CorpusPerVendorTemp)\n",
    "\n",
    "\n",
    "#                 else:\n",
    "#                     pass\n",
    "#         AllCorpus = \".\".join(AllCorpus)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\CP.txt'\n",
    "EnvironmentPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\環境.txt'\n",
    "ServicePath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\服務.txt'\n",
    "DelicacyPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\美味.txt'\n",
    "\n",
    "CP = Training(CPPath)\n",
    "Environment = Training(EnvironmentPath)\n",
    "Service = Training(ServicePath)\n",
    "Delicacy =Training(DelicacyPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['老闆', '味道', '便宜', '划算', '店', '聚餐', '值高', '人', '台大', '品質', '算', '一起', '不錯', '平價', '豆腐', '上菜', '免費', '主菜', '挺', '值得', '喝到', '必點', '時', '試試', '機會', '搭配', '咖哩', '食材', '老闆娘', '白飯', '清爽', '包', '點餐', '不貴', '特別', '一個', '乾淨', '評價', '不飽', '主餐', '醬汁', '少', '裝潢', '小菜', '鹹', '適合', '喜歡', '親切', '比較', '價位', '有點', '好吃', '飯', '再', '馬鈴薯', '無限', '分', '簡單', '推', '柴魚片']\n",
      "['普通', '應該', '價錢', '附近', '加點', '知道', '老闆', '味道', '人', '台大', '品質', '算', '兩顆', '久坐', '青菜', '再來', '接受', '聊天', '還要', '這次', '好了', '趕人', '算是', '分量', '配菜', '不差', '越來越', '要價', '左右', '為主', '便當', '關係', '門口', '卻', '單點', '貴', '最近', '名單', '三顆', '之前', '不錯', '平價', '特別', '一個', '乾淨', '評價', '不飽', '主餐', '醬汁', '少', '裝潢', '小菜', '鹹', '適合', '喜歡', '親切', '比較', '價位', '有點', '好吃']\n",
      "['普通', '應該', '價錢', '加點', '附近', '知道', '老闆', '味道', '便宜', '聚餐', '划算', '店', '值高', '人', '算', '台大', '品質', '一起', '久坐', '這次', '門口', '名單', '青菜', '接受', '聊天', '還要', '好了', '算是', '越來越', '左右', '便當', '關係', '最近', '再來', '不差', '要價', '為主', '卻', '單點', '兩顆', '趕人', '分量', '配菜', '貴', '三顆', '之前', '不錯', '平價', '豆腐', '喝到', '必點', '時', '機會', '搭配', '食材', '老闆娘', '清爽', '不貴', '免費', '值得']\n"
     ]
    }
   ],
   "source": [
    "Training.BuildTrainDic(CP,AllDocRoot, 60)\n",
    "# Training.BuildTrainDic(Environment ,AllDocRoot, 60)\n",
    "# Training.BuildTrainDic(Service ,AllDocRoot, 60)\n",
    "# Training.BuildTrainDic(Delicacy ,AllDocRoot, 60)\n",
    "\n",
    "print(CP.TopNGood)\n",
    "print(CP.TopNNegative)\n",
    "print(CP.TopNFeautures)\n",
    "# print(Environment.TopNFeautures)\n",
    "# print(Service.TopNFeautures)\n",
    "# print(Delicacy.TopNFeautures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
