{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#準備工作\n",
    "# AllDocRoot 為所有評論所在資料夾, json檔\n",
    "AllDocRoot = r\"C:\\Users\\User\\Desktop\\商管\\Final\\TenReviews\"\n",
    "#CP值的csv轉成utf-8 的txt所在位置, github上我放的那幾個\n",
    "CPPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\CP.txt'\n",
    "EnvironmentPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\環境.txt'\n",
    "ServicePath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\服務.txt'\n",
    "DelicacyPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\美味.txt'\n",
    "#  務必下載斷詞字典和停用詞字典放到以下位置, github上有\n",
    "SepDictionaryPath = r'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\jieba\\dict.txt'\n",
    "StopDicPath = r'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\jieba\\stop.txt'\n",
    "jieba.set_dictionary(r'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\jieba\\dict.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "with open(StopDicPath,'r',encoding = 'utf8') as f:\n",
    "    StopWords = f.read().split('\\n')\n",
    "    StopWords[0] = ','\n",
    "    \n",
    "def ChiFeatureSelection(Corpus_list,dic_list,Class_group, n ):\n",
    "    '''\n",
    "    Feautures Selection的方法\n",
    "    Input:Corpus_list, [0] 為標記 0,1 [1]為斷詞後評論\n",
    "          dic_list, set of terms\n",
    "          Class_group, 共幾組，以list表示 i.e. ['0','1']\n",
    "          n, 前幾名term\n",
    "    '''\n",
    "    goodfeatures = []\n",
    "    for term in dic_list:\n",
    "        Xchi = 0\n",
    "        ContingencyTable = []\n",
    "        Tcount= 0\n",
    "        Fcount = 0\n",
    "        for Class in Class_group:\n",
    "            TP = 0\n",
    "            FN = 0\n",
    "            for corpus in Corpus_list:\n",
    "                \n",
    "                if term in corpus[1] and Class == corpus[0]:\n",
    "                    TP += 1\n",
    "                elif term not in corpus[1] and Class == corpus[0]:\n",
    "                    FN += 1\n",
    "            Tcount += TP\n",
    "            Fcount += FN\n",
    "#             print(Tcount)\n",
    "            ContingencyTable.append([TP,FN])\n",
    "#             print(Class)\n",
    "            \n",
    "        Total = (Tcount + Fcount) \n",
    "        T_P = Tcount / Total\n",
    "        N_P = 1 - T_P\n",
    "#         print(T_P,N_P,sep=' ')\n",
    "        for i in ContingencyTable:\n",
    "            T = i[0]\n",
    "            F = i[1]\n",
    "            Class_P = (T + F)/ Total\n",
    "            \n",
    "            Etc = T_P * Class_P\n",
    "            Efc = N_P * Class_P\n",
    "            if N_P ==0:\n",
    "                print(N_P)\n",
    "            Xchi += (T - Etc)**(2) / Etc + (F - Efc)**(2) / Efc\n",
    "        if ContingencyTable[0][0] > ContingencyTable[1][0]:\n",
    "            Postive = '0'\n",
    "        elif ContingencyTable[0][0] < ContingencyTable[1][0]:\n",
    "            Postive = '1'\n",
    "        else:\n",
    "            Postive = 'equal'\n",
    "        goodfeatures.append([Postive,term,Xchi])\n",
    "    goodfeatures.sort(reverse = True, key = lambda x:x[2])\n",
    "    goodfeatures_term = []\n",
    "    for i in goodfeatures:\n",
    "        goodfeatures_term.append([i[0],i[1],i[2]])\n",
    "\n",
    "    return goodfeatures_term[0:n]\n",
    "\n",
    "# def DocsSepbyVendor(ALLDocsRoot):\n",
    "#     import json\n",
    "#     import requests\n",
    "#     import glob\n",
    "#     import os\n",
    "        \n",
    "#     file_list = glob.glob(os.path.join(os.getcwd(), ALLDocsRoot, \"*.json\"))\n",
    "#     CorpusByVendor = dict()\n",
    "        \n",
    "#     for file_path in file_list:\n",
    "#         BaseName = file_path.split('\\\\')[-1].strip('.json')\n",
    "#         with open(file_path,encoding = 'utf-8') as load_test:\n",
    "#             doc =json.load(load_test)\n",
    "\n",
    "#             CorpusPerVendorTemp= []\n",
    "    \n",
    "#             if len(doc['reviews']) != 0:\n",
    "#                 for i in range(len(doc['reviews'])):\n",
    "#                     Text = doc['reviews'][i]['text']\n",
    "#                     Text = re.findall(r'[\\u4e00-\\u9fff]+', Text)\n",
    "#                     Sisstring = ''\n",
    "#                     for i in Text:\n",
    "#                         Sisstring += i \n",
    "#                     words = [s for s in jieba.cut(Sisstring, cut_all=False) if s not in StopWords]\n",
    "#                     CorpusPerVendorTemp.extend(words)\n",
    "#                 CorpusByVendor[BaseName] = CorpusPerVendorTemp\n",
    "#             else:\n",
    "#                  pass\n",
    "#     return CorpusByVendor \n",
    "\n",
    "def Tf_idf(terms , CorpusByVendor,ChiDict):\n",
    "    dic = {} \n",
    "\n",
    "    for item in terms: \n",
    "        if (item not in dic): \n",
    "            dic[item] = 0\n",
    "\n",
    "    for keys in dic.keys():\n",
    "\n",
    "        for vendor in CorpusByVendor.keys():\n",
    "\n",
    "            if (keys in CorpusByVendor[vendor]):\n",
    "                dic[keys] += 1\n",
    "\n",
    "            else:\n",
    "                dic[keys] += 0\n",
    "    dicSorted = sorted(dic.items() ,  key=lambda x: x[1])\n",
    "#     print(dicSorted)\n",
    "    import math\n",
    "    Rank = []\n",
    "    for keys in CorpusByVendor.keys() :\n",
    "        \n",
    "        docfreq = []\n",
    "        docunit = []\n",
    "        N =len(CorpusByVendor.keys())\n",
    "        if len(CorpusByVendor[keys]) != 0:\n",
    "#             print(CorpusByVendor[keys])\n",
    "            for f in dicSorted:\n",
    "                if (f[0] in CorpusByVendor[keys]):\n",
    "                    tf = CorpusByVendor[keys].count(f[0])\n",
    "    #                 N =len(file_list)\n",
    "                    df = dic[f[0]]\n",
    "                    idf = math.log((N / df) ,10)\n",
    "                    tf_idf = tf * idf\n",
    "                else:\n",
    "                    tf_idf = 0\n",
    "                \n",
    "                docfreq.append([tf_idf,ChiDict[f[0]]])\n",
    "\n",
    "            sum_square = 0\n",
    "            for i in docfreq:\n",
    "                sum_square += i[0]**2\n",
    "            if sum_square != 0:\n",
    "                for i in docfreq:\n",
    "                    docunit.append([i[0]/(sum_square**0.5),i[1]])\n",
    "                Score = 0\n",
    "                for i in docunit:\n",
    "                    Score += i[0] * i[1]\n",
    "            else:\n",
    "                    Score = 0\n",
    "            Rank.append([keys,Score])    \n",
    "    Rank.sort(reverse = True,key = lambda x: x[1])\n",
    "    return Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    import jieba\n",
    "    \n",
    "    def __init__(self,Path):\n",
    "        '''\n",
    "        Input: Path, 為訓練集的位置的，UTF-8 txt\n",
    "        Output: Positive, 正面(1)或負面(0)\n",
    "                Name, 店家名\n",
    "                Counter ,該店家第幾篇評論\n",
    "        '''\n",
    "        Corpus = []\n",
    "        with open(Path,'r', encoding = 'utf-8') as text:\n",
    "        #     text.close()\n",
    "            PositiveList = []\n",
    "            NameList = []\n",
    "            CounterList = []\n",
    "            for i in text:\n",
    "                Positive = i.strip('\\n').split('\\t')[0]\n",
    "                Positive = Positive.strip('\\ufeff')\n",
    "                Name = i.strip('\\n').split('\\t')[1].split(',')[0]\n",
    "                Id =int(i.strip('\\n').split('\\t')[1].split(',')[1])\n",
    "                PositiveList.append(Positive)\n",
    "                NameList.append(Name)\n",
    "                CounterList.append(Id)\n",
    "                \n",
    "        self.Positive = PositiveList\n",
    "        self.Name= NameList\n",
    "        self.Counter = CounterList\n",
    "        \n",
    "    def BuildTrainDic(self,ALLDocsRoot,n):\n",
    "        '''\n",
    "        Input:  ALLDocsRoot, 為所有評論的位置，評論為json檔\n",
    "                Positive, 正面(1)或負面(0)\n",
    "                Name, 店家名\n",
    "                Counter ,該店家第幾篇評論\n",
    "                皆為上述產生\n",
    "                n, 前n名的Feautures\n",
    "        Ootput:\n",
    "                self.TopNFeautures,前n名的Feautures\n",
    "                \n",
    "        41~70 對你找出資料夾中訓練集的文章並清掉韓文有幫助，71是結疤斷詞\n",
    "        '''\n",
    "        file_list = glob.glob(os.path.join(os.getcwd(), ALLDocsRoot, \"*.json\"))\n",
    "        Corpus = []\n",
    "        NegativeCorpus = []\n",
    "        NameAndPositive = []\n",
    "        Potential_Features = []\n",
    "        Potential_GFeatures = []\n",
    "        Potential_NFeatures = []\n",
    "        for i in zip(self.Positive,self.Name):\n",
    "            NameAndPositive.append([i[1],i[0]])\n",
    "       \n",
    "        for file_path in file_list:\n",
    "            BaseName = file_path.split('\\\\')[-1].strip('.json')\n",
    "            for NamePositiveAndOrder in zip(NameAndPositive,self.Counter):\n",
    "#                 print(NamePositiveAndOrder[0][0],BaseName)\n",
    "                if BaseName == NamePositiveAndOrder[0][0] :                   \n",
    "                    with open(file_path,encoding = 'utf-8') as load_test:\n",
    "                        doc =json.load(load_test)\n",
    "                        \n",
    "                        if len(doc['reviews']) != 0:\n",
    "                            \n",
    "                            for i in range(len(doc['reviews'])):\n",
    "                                if i == NamePositiveAndOrder[1]:\n",
    "                                    \n",
    "                                    Text = doc['reviews'][i]['text']\n",
    "                                    Text = re.findall(r'[\\u4e00-\\u9fff]+', Text)\n",
    "                                    Sisstring = ''\n",
    "                                    for i in Text:\n",
    "                                        Sisstring += i \n",
    "                                    words = [s for s in jieba.cut(Sisstring, cut_all=False) if s not in StopWords]\n",
    "                                    if NamePositiveAndOrder[0][1] == '1':\n",
    "                                        Corpus.append([NamePositiveAndOrder[0][1],words])\n",
    "#                                         Potential_GFeatures.extend(words)\n",
    "                                        Potential_Features.extend(words)\n",
    "                                       \n",
    "                                    elif NamePositiveAndOrder[0][1] == '0':\n",
    "                                        Corpus.append([NamePositiveAndOrder[0][1],words])\n",
    "#                                         Potential_NFeatures.extend(words)\n",
    "                                        Potential_Features.extend(words)\n",
    "                                    else:\n",
    "                                        return print('Indicatior is neither 1 or 0')\n",
    "\n",
    "        self.Potential_Features = set(Potential_Features)\n",
    "#         self.GoodFeatures = set(Potential_GFeatures)\n",
    "#         self.NegativeFeatures = set(Potential_NFeatures)\n",
    "        \n",
    "        Class_group= ['0','1']\n",
    "        self.TopNFeatures = ChiFeatureSelection(Corpus, self.Potential_Features,Class_group, n)\n",
    "        self.TopNGood = [G[1] for G in self.TopNFeatures if G[0] == '1']\n",
    "        self.TopNNegative = [G[1] for G in self.TopNFeatures if G[0] == '0']\n",
    "        self.TopNFeatures = [G[1] for G in ChiFeatureSelection(Corpus, self.Potential_Features,Class_group, n)]\n",
    "        self.ChiDict ={t[1]:t[2] for t in ChiFeatureSelection(Corpus, self.Potential_Features,Class_group, n)}\n",
    "\n",
    "class Grading:\n",
    "    def __init__(self,ALLDocsRoot):\n",
    "        import json\n",
    "        import requests\n",
    "        import glob\n",
    "        import os\n",
    "\n",
    "        file_list = glob.glob(os.path.join(os.getcwd(), ALLDocsRoot, \"*.json\"))\n",
    "        CorpusByVendor = dict()\n",
    "\n",
    "        for file_path in file_list:\n",
    "            BaseName = file_path.split('\\\\')[-1].strip('.json')\n",
    "            with open(file_path,encoding = 'utf-8') as load_test:\n",
    "                doc =json.load(load_test)\n",
    "\n",
    "                CorpusPerVendorTemp= []\n",
    "\n",
    "                if len(doc['reviews']) != 0:\n",
    "                    for i in range(len(doc['reviews'])):\n",
    "                        Text = doc['reviews'][i]['text']\n",
    "                        Text = re.findall(r'[\\u4e00-\\u9fff]+', Text)\n",
    "                        Sisstring = ''\n",
    "                        for i in Text:\n",
    "                            Sisstring += i \n",
    "                        words = [s for s in jieba.cut(Sisstring, cut_all=False) if s not in StopWords]\n",
    "                        CorpusPerVendorTemp.extend(words)\n",
    "                    CorpusByVendor[BaseName] = CorpusPerVendorTemp\n",
    "                else:\n",
    "                     pass\n",
    "        self.CorpusByVendor = CorpusByVendor\n",
    "        \n",
    "    def WeightedScore(self,Training):     \n",
    "        SepCorpus = self.CorpusByVendor\n",
    "        \n",
    "        GoodScore = {t[0]:t[1] for t in Tf_idf(Training.TopNGood,SepCorpus,Training.ChiDict)}\n",
    "        BadScore = {t[0]:t[1] for t in Tf_idf(Training.TopNNegative,SepCorpus,Training.ChiDict)}\n",
    "\n",
    "        WeightedScore = {}\n",
    "\n",
    "        for key in GoodScore.keys():\n",
    "            WeightedScore[key] = GoodScore[key] - BadScore[key]\n",
    "        SortedWeightedScore = {k: v for k, v in sorted(WeightedScore.items(),reverse = True, key=lambda item: item[1])}\n",
    "        self.SortedWeightedScore = SortedWeightedScore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ooh Cha Cha 自然食科技大樓 _ Hooch11-20': 13676.894768292083, 'Barkers11-20': 10561.096261568719, '蕭家傳統小吃11-20': 10096.494903504652, 'Pasta_202_20Go11-20': 9709.301034403514, '川味辛亥小吃11-20': 9298.708925450816, '小飯館兒11-20': 8430.912332972479, 'Riad_20Chi_20Chi異國料理11-20': 8284.074405984986, '松田日式飯糰11-20': 8282.643704110655, '順園小館11-20': 8057.971749058761, '韓天閣11-20': 7777.169120845421, '柒食貳11-20': 7582.097321067908, '鳳城臘味家_20(百合店)11-20': 7193.275225208072, '淺草日式飯糰11-20': 6725.5205265674485, '三米三小館11-20': 6692.357348245119, '大聲公 台大牛肉麵店11-20': 6544.103554729749, '小六手工拉麵11-20': 6493.352179020616, '香港亨記(公館店)11-20': 5995.246705289381, '巧味快餐11-20': 5880.509008961231, '伊斯坦堡土耳其餐酒館11-20': 5778.922272440188, '瑪德蓮小酒館11-20': 5748.434821910978, 'Sababa_20Pita_20Bar沙巴巴中東美食11-20': 5576.573707310175, '牛洞食堂11-20': 5446.7545920282755, 'Mr._20拉麵11-20': 5439.680724574893, '玉欣珍傳統美食坊11-20': 5415.042938589268, '大家素食11-20': 5396.540095360027, '鑫吉野烤肉飯公館店11-20': 5389.674510158315, '憶馬當鮮 馬來西亞風味料理11-20': 5340.788646625926, '凱利義式餐廳11-20': 4991.072272325784, '祥記號美食小吃11-20': 4716.71138621765, '二八麵堂11-20': 4695.699608739527, '曉鹿鳴樓11-20': 4664.075111356569, '大李水餃11-20': 4445.146382269122, '願有記台大店11-20': 4403.25940036642, '阿里媽媽南洋料理11-20': 4390.717902768423, '河內美食（Hanoi Food)11-20': 4009.776430515609, '新卡莎素食西餐廳11-20': 3855.846914858197, '直火人 直火燒肉丼飯屋11-20': 3721.3322444800106, '四麵八方11-20': 3550.2460359243996, '老先覺功夫窯燒鍋台北公館店11-20': 3501.409630063783, '泰豐味11-20': 3409.93124755411, '維綸麵食館11-20': 3346.736107547833, '台南周氏冰鎮滷味(和平店)11-20': 3312.8378067539134, '如來素食樂園11-20': 3192.5473515349313, '長興小舖11-20': 3186.353624125326, '韓庭州韓國料理11-20': 3164.7220888912616, '俄羅斯城堡11-20': 3054.506274965952, '茗香園冰室 - 公館店11-20': 3028.4116363406174, '好處_20Have_20A_20Nice_20Day11-20': 2972.6302655336767, '西藏廚房11-20': 2968.6577551808878, '貞有緣素食11-20': 2684.896506106743, '笑嘻嘻港式現炒飯麵11-20': 2664.2828938290622, '麵工坊義大利麵 大安店11-20': 2641.0066235082923, '麵之彩11-20': 2563.365561294242, '微笑廚房洋食館11-20': 2454.0229469504975, '首都烘焙餐廳-公館店11-20': 2315.4584275250472, '胖東西廚房_20Osteria_20by_20Vincent11-20': 2224.1938059522417, '季丼屋 - 日本丼飯11-20': 2211.378676060336, '老爹De蛋蛋屋11-20': 2097.5218776812435, '通哥串燒居酒屋11-20': 1941.9893314490328, '全國食養健康素食自助餐 大安復興店11-20': 1793.504261247621, 'Living One11-20': 1714.6457160567006, 'Gugo Kitchen 無國界料理11-20': 1556.739233543407, '大埔鐵板燒 公館店11-20': 1521.1925383544913, '3_20Idiots_20Toast_20_20Curry_20三個傻瓜蔬食印度餐廳-公館店11-20': 1441.804697796906, '大盛豬排專門店11-20': 1373.5811365919508, 'EMALI伊瑪利義大利麵館11-20': 1224.1358261553833, '豪香熱炒11-20': 1191.6423077485233, '麒雲。餐酒藝術餐廳11-20': 1108.9445507662876, '雲香亭11-20': 1047.0144987130261, '韓江館銅盤烤肉11-20': 1044.9312484525344, 'Lacuz 泰食-樂 餐廳11-20': 1028.5182608503856, '曼谷燒11-20': 973.1192069914032, 'L.A.F BURGER 拉芙漢堡11-20': 901.9862000727699, 'Miss energy低GI廚房公館店11-20': 896.6202132866292, '湄賽雲泰料理11-20': 860.7280375005284, '瑞榮燒臘11-20': 853.8643965011834, '窩巷弄11-20': 801.2073299344811, '郭董麻辣牛肉麵11-20': 764.2586018516085, '馬祖麵館11-20': 737.0286377303546, '親來食堂11-20': 539.0782023456122, '得記麻辣脆皮臭豆腐11-20': 496.84591938613994, '龍記炒燴11-20': 395.0406652218735, '小李子蘭州牛肉拉麵館11-20': 357.48149417976674, '找碗11-20': 280.9928761583287, '蠶居11-20': 276.00230190867296, '逗豆舖11-20': 156.98572008336123, '銀座越南美食11-20': 154.42658258921801, 'THAIHAND_20右手餐廳_20公館店11-20': 107.37638110169792, '麻吉食堂11-20': 75.53461327234982, 'Ville_20Cafe11-20': 49.996304048476304, 'Dianwei_20Yunnan_20Cuisine11-20': 47.22448415974395, '上好魚翅燕窩11-20': 0, '泰正點泰式料理 NICE THAI FOOD11-20': -0.08793643594617606, '尚家香雲南美味麵食館11-20': -39.4342566255018, 'Arthur健康輕食餐飲11-20': -40.71502011060875, '厚宅11-20': -41.46912341503776, '鴉片粉圓創始店11-20': -46.7051455405126, '海賊食堂11-20': -214.13382788035233, '公館-咖哩先生11-20': -565.2629154143142, '光一肆號11-20': -605.7196717952938, '吃吐吧11-20': -619.9026846200213, '銀咖喱公館總店11-20': -653.525750286848, 'Curry Kitchen咖哩廚房(台大辛亥店)11-20': -726.1000938675425, '韓喜堂11-20': -755.9402644575384, '台大牛莊11-20': -979.71108599328, '呷飯團11-20': -981.9243765664687, '壹森泰食堂~師大第一腿(公館店）11-20': -1148.8170971782802, '易牙居餐廳11-20': -1208.9081364089016, '甘丹燒鐵板11-20': -1372.7893680451107, '蒙娜家廚11-20': -1446.879623177374, '瓦崎燒烤火鍋 敦南店11-20': -1617.8749467122852, '新馬辣經典麻辣鍋-公館店11-20': -1895.1029430041854, 'Wen_s Kitchen 文的廚房11-20': -1901.2013332268707, '母女的店11-20': -1912.1909791323778, '咖哩戰線11-20': -1929.6279160102094, 'Tulip TimeOut 西門店11-20': -2034.9976812609093, '翊進上香川海鮮饌食館11-20': -2070.448229301088, '麥子磨麵11-20': -2196.712678924163, '山丼11-20': -2206.711259217327, '蘇活義大利麵坊11-20': -2447.460357120668, '指有雞飯_20CHICKEN_20RICE_20ONLY11-20': -2564.4922536323975, '鳳城燒臘粵菜11-20': -2577.745795032908, '揪食堂_20韓國餐館11-20': -2626.653963375067, '義饗食堂11-20': -2691.899586330648, '艾茉蕾披薩店11-20': -2695.1953153386894, '真芳-大安店11-20': -2727.0295385486825, '阿剛泰式主題餐廳11-20': -2804.9597503562727, '紫牛平價牛排11-20': -2871.3189415456836, '我家涼麵11-20': -3031.104503473849, '泰街頭11-20': -3042.8574923919114, '魯山人和風壽喜燒鍋物11-20': -3173.356159467512, '發現義大利麵11-20': -3200.273685731174, '漁人食舖11-20': -3356.8906851183838, '十二巷拉麵11-20': -3399.0910435439328, '鍋in百元風味火鍋11-20': -3411.268538438486, '阿英滷肉飯11-20': -3484.3707977449376, '溏老鴨平價小火鍋11-20': -3629.4073558249675, '集客人間茶館-台大店11-20': -3641.284423220508, '池先生 Kopitiam (公館店)11-20': -3682.137758980709, '邦食堂11-20': -3728.8932013301237, '吉野家台大店11-20': -3732.74841019417, '七里亭Bar·茶飲簡餐11-20': -3778.0702436592255, '大福利排骨大王11-20': -3788.15991219412, '赤神日式豬排公館店11-20': -3808.4324336638965, 'I’m_20Pasta_20和平店11-20': -3814.9996063255294, '希臘左巴11-20': -3837.1176583625493, '愛樂廚房11-20': -3869.0327196914077, '3隻貓頭鷹文創11-20': -3924.4809900879864, '南台虱目魚之家11-20': -4010.01702647988, '至香園_20ZHI_20XIANG_20YUAN_20沙茶牛肉乾麵11-20': -4066.3480915316395, '越南清化河粉11-20': -4145.54931823426, 'POST霞飛驛歐法點餐11-20': -4329.597170429435, 'DJ_20House好食居11-20': -4404.992091825534, '小川拉麵11-20': -4582.978759051355, '合益佳雞肉飯11-20': -4609.904625994297, 'Kitchen6611-20': -4625.924323290299, '忠誠山東蔥油餅_20-_20此燈亮有餅11-20': -4756.583550356154, '正香馬來西亞餐室（原正香海南雞飯）11-20': -4764.334218709297, '我家吃麵11-20': -4766.863210337262, '源士林粥品11-20': -5060.10894356147, '興隆涼麵11-20': -5078.022471402588, '貝倫烘焙餐坊_20台北店11-20': -5577.112645969351, '格芮潘義式廚房11-20': -5603.027225828224, '狂愛咖哩 Just Love Curry11-20': -5988.095407077719, '長榮發池上飯包 池上便當11-20': -6047.659209997082, '幸好沒錯過你 Master K.11-20': -6147.120893049534, '義麵麵11-20': -6629.921482292304, '七里亭11-20': -7042.877256011594, '泰國小館11-20': -7282.102063436345, '李記水餃11-20': -7368.303954996545, '稻咖哩11-20': -7598.377692500924, '狗一下居酒食堂-公館店11-20': -7914.253837504997, '台灣第一腿(泰式碳烤)11-20': -8527.351835951726, '鷹流東京豚骨拉麵-極匠11-20': -8764.05058440299, '粗茶淡飯人文茶館11-20': -9955.313712258412, '一品山西刀削麵之家11-20': -10270.07099862852, 'Celeste Noodle House11-20': -12178.233615092893}\n"
     ]
    }
   ],
   "source": [
    "#建立CP字典\n",
    "AllDocRoot = r\"C:\\Users\\User\\Desktop\\商管\\Final\\TenReviews\" #所有評論地點\n",
    "CPPath = r'C:\\Users\\User\\Documents\\GitHub\\2019fall_final\\CP.txt' #確認訓練集標號文件地點\n",
    "\n",
    "CPTrain = Training(CPPath) #初始化訓練文件，\n",
    "\n",
    "Training.BuildTrainDic(CPTrain, AllDocRoot, 100) #建立下述物件 而100為找出前100個有判別力的斷詞(不分好壞)\n",
    "\n",
    "# print(CPTrain.TopNFeatures) # 回傳100判別力的斷詞(不分好壞)\n",
    "# print(CPTrain.TopNGood) # 回傳100個中有判斷力的正面斷詞\n",
    "# print(CPTrain.TopNNegative) # 回傳100個中有判斷力負面斷詞 前兩者數量相加應等於TopNFeatures\n",
    "# print(CPTrain.ChiDict) # 100個term的卡方值字典 待會計算wighting會用到\n",
    "\n",
    "CPFinal = Grading(AllDocRoot) #初始化排名字典\n",
    "Grading.WeightedScore(CPFinal, CPTrain) # 建立排名字典 數字越大表示 其正負相抵後的在該項正面指標越高\n",
    "# print(CPFinal.SortedWeightedScore) #字典結果 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
